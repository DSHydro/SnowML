{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qXoOmP2oEHl3"
   },
   "source": [
    "# **Tutorial** - Time Series Prediction of Snow Water Equivalent (SWE) Using LSTM in PyTorch With MLFLOW Logging\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is a slightly modified version of the protoype model provided to the Frosty Dawgs team, demonstrating an LSTM model to predict SWE on several Huc10 units in Skagit Basin.  It represents the starting point for the team's work and we thank the authors of the original prototype model.  This notebook modifies the originally provided notebook only as follow: (1) updates the folders for uploading data; (2) adds a calculation of KGE goodness of fit metrics for comparison with later versions of of the model by the Frosty Dawgs Team; and (3) adds ML Flow tracking capabilities. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WX11raceEEzh"
   },
   "source": [
    "First, we import all the necessary libraries such as `torch`, `numpy`, `pandas`, and others for data preprocessing, model building, and evaluation. These libraries are key for handling data, neural networks, and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tpEv280r4LPs",
    "outputId": "47e86071-eb30-4695-ba19-67b926dd1c5d"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import gdown\n",
    "import torch\n",
    "import warnings\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.utils.data as data\n",
    "\n",
    "from torch import nn\n",
    "#from tqdm.autonotebook import tqdm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "DTYPE = torch.float32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t6KcXG_ptSHA"
   },
   "source": [
    "##  Set the MLflow tracking server\n",
    "\n",
    "Note: Assumes you have already started mlflow by opening a terminal withy mlflow installed and running mlflow uo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "meXh6UVotPcF",
    "outputId": "f9a002d4-24e6-4493-95c4-d3420e9b48dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='s3://sues-test/199', creation_time=1740199897768, experiment_id='199', last_update_time=1740199897768, lifecycle_stage='active', name='ProtoType_Results', tags={}>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set our tracking server uri for logging\n",
    "tracking_uri = \"arn:aws:sagemaker:us-west-2:677276086662:mlflow-tracking-server/dawgsML\"\n",
    "mlflow.set_tracking_uri(tracking_uri)\n",
    "\n",
    "# Create a new MLflow Experiment called \"LSTM\"\n",
    "mlflow.set_experiment(\"ProtoType_Results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YFoVfo5-EaUQ"
   },
   "source": [
    "## Data Prepration "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wrf-skagit-1711000504-mean.csv', 'wrf-skagit-1711000505-mean.csv', 'wrf-skagit-1711000506-mean.csv', 'wrf-skagit-1711000507-mean.csv', 'wrf-skagit-1711000508-mean.csv', 'wrf-skagit-1711000509-mean.csv', 'wrf-skagit-1711000511-mean.csv']\n",
      "['wus-sr-skagit-1711000504-mean-swe.csv', 'wus-sr-skagit-1711000505-mean-swe.csv', 'wus-sr-skagit-1711000506-mean-swe.csv', 'wus-sr-skagit-1711000507-mean-swe.csv', 'wus-sr-skagit-1711000508-mean-swe.csv', 'wus-sr-skagit-1711000509-mean-swe.csv', 'wus-sr-skagit-1711000511-mean-swe.csv']\n"
     ]
    }
   ],
   "source": [
    "# This function creates a list of filenames that contain the swe and wrf data respectively \n",
    "\n",
    "wrf_file_pattern = \"wrf-skagit-17110005{}-mean.csv\"\n",
    "swe_file_pattern = \"wus-sr-skagit-17110005{}-mean-swe.csv\"\n",
    "file_no_list = ['04', '05', '06', '07', '08', '09', '11']  # Note there is no 10\n",
    "filenames1 = [wrf_file_pattern.format(file_no) for file_no in file_no_list]\n",
    "filenames2 = [swe_file_pattern.format(file_no) for file_no in file_no_list]\n",
    "\n",
    "print(filenames1)\n",
    "print(filenames2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "giNglL3OF5xh"
   },
   "outputs": [],
   "source": [
    "# This function normalizes the data using the Z-score formula, which helps to standardize the features\n",
    "\n",
    "def z_score_normalize(df):\n",
    "\tnormalized_df = df.copy()\n",
    "\n",
    "\tfor column in df.columns:\n",
    "\t\tcolumn_mean = df[column].mean()\n",
    "\t\tcolumn_std = df[column].std()\n",
    "\t\tnormalized_df[column] = (df[column] - column_mean) / column_std\n",
    "\n",
    "\treturn normalized_df\n",
    "\n",
    "# This function filters and merges two datasets (WRF and WUS) based on date ranges and resamples the data. It saves the filtered data as a new CSV:\n",
    "\n",
    "def filter_and_merge_data(wrf_file, wus_file, filter_start_date, filter_end_date, filtered_data_start_data, filtered_data_end_data):\n",
    "    # read WRF data\n",
    "    #file_number = wrf_file.split('-')[5]\n",
    "    wrf = pd.read_csv(wrf_file)\n",
    "    wrf['time'] = pd.to_datetime(wrf['time'])\n",
    "    wrf.set_index('time', inplace=True)\n",
    "\n",
    "    # Filter based on time index range\n",
    "    wrf_filtered = wrf.loc[(wrf.index > filter_start_date) & (wrf.index < filter_end_date)]\n",
    "\n",
    "    # Resampling the data\n",
    "    wrf_resampled = wrf_filtered.resample('D').mean()\n",
    "\n",
    "    # read WUS data\n",
    "    wus = pd.read_csv(wus_file)\n",
    "    wus['time'] = pd.to_datetime(wus['time'])\n",
    "    wus.set_index('time', inplace=True)\n",
    "\n",
    "    # Filter based on time index range\n",
    "    wus_filtered = wus.loc[wus.index < filter_end_date]\n",
    "\n",
    "    # Merging the data\n",
    "    data = pd.merge(wrf_resampled, wus_filtered, left_index=True, right_index=True, how='inner')\n",
    "    data = data[['precip', 'tair', 'mean']]\n",
    "    data.rename(columns={'mean': 'SWE_Post'}, inplace=True)\n",
    "\n",
    "    # Save the merged data to a new CSV file\n",
    "    #try:\n",
    "        #data.to_csv(f'filtered_data/filtered_csv_{file_number}.csv')\n",
    "        #print('File Saved !!')\n",
    "    #except:\n",
    "        #print('File save failed !!')\n",
    "\n",
    "    # Filter the final data based on the date range\n",
    "    filtered_data = data.loc[(data.index >= filtered_data_start_data) & (data.index <= filtered_data_end_data)]\n",
    "\n",
    "    return data, filtered_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b2QhMko3Eppc"
   },
   "source": [
    "## **Creating Dataset for Time Series Prediction**\n",
    "\n",
    "This function transforms time-series data into a format suitable for model training. It uses the lookback parameter to determine how many previous time steps to consider as input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "UfRipIqnGBJ-"
   },
   "outputs": [],
   "source": [
    "def create_dataset(dataset, lookback):\n",
    "    \"\"\"Transform a time series into a prediction dataset\n",
    "\n",
    "    Args:\n",
    "        dataset: A pandas DataFrame of time series data\n",
    "        lookback: Size of window for prediction\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(len(dataset) - lookback):\n",
    "        feature = dataset.iloc[i:(i + lookback), :2].values  # Select first two columns\n",
    "        target = dataset.iloc[i + lookback, -1:].values  # Selects the last column dynamically\n",
    "        X.append(feature)\n",
    "        y.append(target)\n",
    "    return torch.tensor(X, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gv7SEozFE_Iw"
   },
   "source": [
    "## **Snow Model (LSTM Neural Network)**\n",
    "\n",
    "This is a simple LSTM-based neural network model designed for predicting SWE_Post values. The model uses one LSTM layer followed by a linear layer and LeakyReLU activation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "jx8jdPyXGDFO"
   },
   "outputs": [],
   "source": [
    "class SnowModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_class, num_layers, dropout):\n",
    "        super(SnowModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        self.lstm1 = nn.LSTM(input_size, hidden_size, num_layers, dropout=self.dropout, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size, num_class)\n",
    "        self.leaky_relu = nn.LeakyReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        device = x.device\n",
    "        hidden_states = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        cell_states = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        out, _ = self.lstm1(x, (hidden_states, cell_states))\n",
    "        out = self.linear(out[:, -1, :])\n",
    "        out = self.leaky_relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SPU_2MkPFDuR"
   },
   "source": [
    "## **Training the Model**\n",
    "\n",
    "This function trains the model on the training data for a specified number of epochs and batch size. It also prints the Root Mean Square Error (RMSE) every 10 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "-ygh0YurGGNk"
   },
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, loss_fn, X_train, y_train, n_epochs, batch_size):\n",
    "\tloader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(X_train, y_train), shuffle=True, batch_size=batch_size)\n",
    "\tepoch_losses = []\n",
    "\n",
    "\tfor epoch in  range(n_epochs):\n",
    "\t\tepoch_loss = 0.0\n",
    "\t\tmodel.train()\n",
    "\t\tfor X_batch, y_batch in loader:\n",
    "\t\t\ty_pred = model(X_batch)\n",
    "\t\t\tloss = loss_fn(y_pred, y_batch)\n",
    "\t\t\toptimizer.zero_grad()\n",
    "\t\t\tloss.backward()\n",
    "\t\t\toptimizer.step()\n",
    "\t\t\tepoch_loss += loss.item()\n",
    "\t\t# Validation\n",
    "\t\tif epoch % 10 != 0:\n",
    "\t\t\tcontinue\n",
    "\n",
    "\t\tmodel.eval()\n",
    "\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\ty_pred = model(X_train)\n",
    "\t\t\ttrain_rmse = np.sqrt(loss_fn(y_pred, y_train))\n",
    "\t\t\tprint(f\"Epoch {epoch}: train RMSE {train_rmse:.4f}\")\n",
    "\n",
    "\t\tepoch_losses.append(epoch_loss / len(loader))\n",
    "\n",
    "\treturn epoch_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bU1qsT1fFJGb"
   },
   "source": [
    "## **Predicting and Plotting Results**\n",
    "\n",
    "This function predicts values on the training and test datasets and visualizes the predictions compared to the actual SWE_Post values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "fpTDgqWkGKkh"
   },
   "outputs": [],
   "source": [
    "def predict(data, model, X_train,X_test, lookback, train_size, huc_no):\n",
    "    data = data.astype(object)\n",
    "    with torch.no_grad():\n",
    "        train_plot = np.full_like(data['SWE_Post'].values, np.nan, dtype=float)\n",
    "        y_pred = model(X_train)\n",
    "        print(y_pred.shape)\n",
    "        y_pred_new = y_pred[:,  -1].unsqueeze(1)\n",
    "        print(y_pred_new.shape)\n",
    "        print(type(lookback),type(train_size))\n",
    "        train_plot[lookback:train_size] = y_pred_new.numpy().flatten()\n",
    "\n",
    "        # shift test predictions for plotting\n",
    "        test_plot = np.full_like(data['SWE_Post'].values, np.nan, dtype=float)\n",
    "        test_plot[train_size+lookback:len(data)] = model(X_test)[:,  -1].unsqueeze(1).numpy().flatten()\n",
    "\n",
    "    # plot\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))  # Create figure explicitly\n",
    "    ax.plot(data.index, data['SWE_Post'], c='b', label='Actual')\n",
    "    ax.plot(data.index, train_plot, c='r', label='Train Predictions')\n",
    "    ax.plot(data.index[train_size+lookback:], test_plot[train_size+lookback:], c='g', label='Test Predictions')\n",
    "    ax.legend()\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel('SWE_Post')\n",
    "    ttl = f\"30_SWE_Post_Predictions_for_huc_{huc_no}\"\n",
    "    ax.set_title(ttl)\n",
    "    plt.show()\n",
    "\n",
    "    fig.savefig(f\"{ttl}.png\", bbox_inches='tight')\n",
    "    mlflow.log_artifact(f\"{ttl}.png\")\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P9f0_Uv-FSB-"
   },
   "source": [
    "## **Model Evaluation**\n",
    "This function evaluates the model using standard metrics such as Mean Squared Error (MSE), Mean Absolute Error (MAE), and R-squared score (R2). In addition, Kling-gupta-efficiency (KGE) added by the Frosty Dawgs team. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kling_gupta_efficiency(y_true, y_pred):\n",
    "    r = np.corrcoef(y_true.ravel(), y_pred.ravel())[0, 1] # Correlation coefficient\n",
    "    alpha = np.std(y_pred) / np.std(y_true)  # Variability ratio\n",
    "    beta = np.mean(y_pred) / np.mean(y_true)  # Bias ratio\n",
    "    kge = 1 - np.sqrt((r - 1)**2 + (alpha - 1)**2 + (beta - 1)**2)\n",
    "    print(f\"r: {r}, alpha: {alpha}, beta: {beta}\")\n",
    "    return kge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "fVbyPyfdHM_8"
   },
   "outputs": [],
   "source": [
    "def evaluate_metrics(model, X_train, y_train, X_test, y_test):\n",
    "    with torch.no_grad():\n",
    "        y_train_pred = model(X_train)\n",
    "        y_test_pred = model(X_test)\n",
    "\n",
    "    train_mse = mean_squared_error(y_train.numpy(), y_train_pred.numpy())\n",
    "    test_mse = mean_squared_error(y_test.numpy(), y_test_pred.numpy())\n",
    "    train_mae = mean_absolute_error(y_train.numpy(), y_train_pred.numpy())\n",
    "    test_mae = mean_absolute_error(y_test.numpy(), y_test_pred.numpy())\n",
    "    train_r2 = r2_score(y_train.numpy(), y_train_pred.numpy())\n",
    "    test_r2 = r2_score(y_test.numpy(), y_test_pred.numpy())\n",
    "\n",
    "    test_kge = kling_gupta_efficiency(y_test.numpy(), y_test_pred.numpy())  # Fixed function call\n",
    "    train_kge = kling_gupta_efficiency(y_train.numpy(), y_train_pred.numpy())  # Fixed variable name\n",
    "\n",
    "    return [train_mse, test_mse, train_mae, test_mae, train_r2, test_r2, train_kge, test_kge]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "C6oA7LyXHQGd"
   },
   "outputs": [],
   "source": [
    "def  get_csv_filenames(directory):\n",
    "  \"\"\" Returns a sorted list of CSV filenames from the given directory.\"\"\"\n",
    "  return  sorted([f for f in os.listdir(directory)  if f.endswith('.csv')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EHb8t2oBFZ2g"
   },
   "source": [
    "## **Running the Pipeline**\n",
    "\n",
    "This section retrieves the filenames from the dataset directories, filters and merges data, and finally trains and evaluates the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "OTl5FU3cHQ32",
    "outputId": "61191c3f-48ab-4ebe-ff7e-5a6fd62c8753",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Files: wrf-skagit-1711000504-mean.csv and wus-sr-skagit-1711000504-mean-swe.csv\n",
      "precip      0\n",
      "tair        0\n",
      "SWE_Post    0\n",
      "dtype: int64\n",
      "Empty DataFrame\n",
      "Columns: [precip, tair, SWE_Post]\n",
      "Index: []\n",
      "precip      0\n",
      "tair        0\n",
      "SWE_Post    0\n",
      "dtype: int64\n",
      "6667 3285\n",
      "\n",
      "Lookback: 180\n",
      "Epoch 0: train RMSE 0.1250\n",
      "Epoch 10: train RMSE 0.0613\n",
      "Epoch 20: train RMSE 0.0314\n",
      "ðŸƒ View run abrasive-lamb-521 at: https://us-west-2.experiments.sagemaker.aws/#/experiments/199/runs/32e4c0446cd74e4c80f519b9ae766090\n",
      "ðŸ§ª View experiment at: https://us-west-2.experiments.sagemaker.aws/#/experiments/199\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 82\u001b[0m\n\u001b[1;32m     79\u001b[0m X_test_snotel, y_test_snotel \u001b[38;5;241m=\u001b[39m create_dataset(test_main, lookback)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# TO DO - REVERT NUMBER OF EPOCHS TO 200 TO MATCH ORIG NOTEBOOK \u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_snotel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_snotel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn_snotel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_snotel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_snotel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[1;32m     83\u001b[0m predict(data,model_snotel,  X_train_snotel,X_test_snotel, lookback, train_size_main, huc_no)\n\u001b[1;32m     84\u001b[0m snotel_metrics \u001b[38;5;241m=\u001b[39m evaluate_metrics(model_snotel, X_train_snotel, y_train_snotel, X_test_snotel, y_test_snotel)\n",
      "Cell \u001b[0;32mIn[8], line 12\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, optimizer, loss_fn, X_train, y_train, n_epochs, batch_size)\u001b[0m\n\u001b[1;32m     10\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(y_pred, y_batch)\n\u001b[1;32m     11\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 12\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     14\u001b[0m epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/autograd/graph.py:769\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    770\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define the hyperparameters\n",
    "input_size=2\n",
    "hidden_size=2**6\n",
    "num_class=1\n",
    "num_layers=1\n",
    "dropout = 0.5\n",
    "\n",
    "learning_rate = 1e-3 #3e-3\n",
    "n_epochs = 30\n",
    "train_size_fraction = 0.67\n",
    "lookback_values =  [180]\n",
    "\n",
    "\n",
    "with mlflow.start_run():\n",
    "    # log all the params\n",
    "    mlflow.log_param(\"Training From\", \"Prototype Notebook\")\n",
    "    mlflow.log_param(\"input_size\", input_size)\n",
    "    mlflow.log_param(\"hidden_size\", hidden_size)\n",
    "    mlflow.log_param(\"num_class\", num_class)\n",
    "    mlflow.log_param(\"num_layers\", num_layers)\n",
    "    mlflow.log_param(\"dropout\", dropout)\n",
    "    mlflow.log_param(\"learning_rate\", learning_rate)\n",
    "    mlflow.log_param(\"train_size_fraction\", train_size_fraction)\n",
    "    mlflow.log_param(\"lookback_values\", lookback_values)\n",
    "    mlflow.log_param(\"epochs\", 30) # n_epochs is 30 above but code below overrides, as in orig notebook\n",
    "\n",
    "    model_snotel = SnowModel(input_size, hidden_size, num_class, num_layers, dropout)\n",
    "    optimizer_snotel = optim.Adam(model_snotel.parameters())\n",
    "    loss_fn_snotel = nn.MSELoss()\n",
    "\n",
    "    # List the files together, assuming they are related in chronological order and should be compared one-to-one\n",
    "    for file1, file2 in zip(filenames1, filenames2):\n",
    "        wrf_file = file1\n",
    "        wus_file = file2\n",
    "        print(f\" Files: {wrf_file} and {wus_file}\")\n",
    "        huc_suff = file1[-11:-9]\n",
    "        huc_no = f\"17110005{huc_suff}\"\n",
    "\n",
    "        # Example usage of filter_and_merge_data\n",
    "        filter_start_date = '1984-10-01'\n",
    "        filter_end_date = '2011-12-31'\n",
    "        filtered_data_start_data = '2005-01-01'\n",
    "        filtered_data_end_data = '2007-12-31'\n",
    "\n",
    "        # Assuming filter_and_merge_data is a function you have defined elsewhere\n",
    "        data, filtered_data = filter_and_merge_data(wrf_file, wus_file, filter_start_date, filter_end_date, filtered_data_start_data, filtered_data_end_data)\n",
    "\n",
    "        # train-test split for time series\n",
    "\n",
    "        print(data.isna().sum())\n",
    "        data = data.fillna(method='bfill')\n",
    "\n",
    "        nan_rows = data[data.isna().any(axis=1)]\n",
    "        print(nan_rows)\n",
    "\n",
    "        print(data.isna().sum())\n",
    "        train_size_main = int(len(data) * 0.67)\n",
    "        test_size_main = len(data) - train_size_main\n",
    "        train_main, test_main = data[:train_size_main], data[train_size_main:]\n",
    "\n",
    "        print(train_size_main,test_size_main)\n",
    "\n",
    "\n",
    "        # train-test split for time series\n",
    "        test_size_filtered = int(len(filtered_data))\n",
    "        test_filtered = filtered_data[:train_size_main]\n",
    "\n",
    "\n",
    "        # Usage example\n",
    "        lookback_values =  [180]\n",
    "        results = []\n",
    "\n",
    "        for lookback in lookback_values:\n",
    "            print(f\"\\nLookback: {lookback}\")\n",
    "            start_time = time.time()\n",
    "\n",
    "            # Snotel dataset\n",
    "            X_train_snotel, y_train_snotel = create_dataset(train_main, lookback)\n",
    "            X_test_snotel, y_test_snotel = create_dataset(test_main, lookback)\n",
    "\n",
    "            # TO DO - REVERT NUMBER OF EPOCHS TO 200 TO MATCH ORIG NOTEBOOK \n",
    "            train_model(model_snotel, optimizer_snotel, loss_fn_snotel, X_train_snotel, y_train_snotel, n_epochs=n_epochs, batch_size=8) \n",
    "            predict(data,model_snotel,  X_train_snotel,X_test_snotel, lookback, train_size_main, huc_no)\n",
    "            snotel_metrics = evaluate_metrics(model_snotel, X_train_snotel, y_train_snotel, X_test_snotel, y_test_snotel)\n",
    "            print(snotel_metrics)\n",
    "            elapsed_time = time.time() - start_time\n",
    "\n",
    "            results.append([lookback, 'snotel', 'train_mse', snotel_metrics[0], elapsed_time])\n",
    "            results.append([lookback, 'snotel', 'test_mse', snotel_metrics[1], elapsed_time])\n",
    "            results.append([lookback, 'snotel', 'train_mae', snotel_metrics[2], elapsed_time])\n",
    "            results.append([lookback, 'snotel', 'test_mae', snotel_metrics[3], elapsed_time])\n",
    "            results.append([lookback, 'snotel', 'train_r2', snotel_metrics[4], elapsed_time])\n",
    "            results.append([lookback, 'snotel', 'test_r2', snotel_metrics[5], elapsed_time])\n",
    "            results.append([lookback, 'snotel', 'train_kge', snotel_metrics[6], elapsed_time])\n",
    "            results.append([lookback, 'snotel', 'test_kge', snotel_metrics[7], elapsed_time])\n",
    "\n",
    "            mlflow.log_metric(f\"{huc_no}_train_mse\", snotel_metrics[0])\n",
    "            mlflow.log_metric(f\"{huc_no}_test_mse\", snotel_metrics[1])\n",
    "            mlflow.log_metric(f\"{huc_no}_train_kge\", snotel_metrics[6])\n",
    "            mlflow.log_metric(f\"{huc_no}_test_kge\", snotel_metrics[7])\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        # Create a DataFrame for the results\n",
    "        df_results = pd.DataFrame(results, columns=['Lookback', 'Dataset', 'Metric', 'Value', 'Time Taken (s)'])\n",
    "\n",
    "        # Print the DataFrame\n",
    "        print(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aF_rDY_1EDfl"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PHAz5A8CIli2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
