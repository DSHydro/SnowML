{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "851f2451-e741-45ed-bfcd-7c5edc178634",
   "metadata": {},
   "source": [
    "# Notebook to download MLFlow Metrics to a local file "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02504c4c-4d89-4e15-99df-dce076ac914e",
   "metadata": {},
   "source": [
    "# Step 0 - Set up Notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a4332eb-7cfb-4393-b40c-b03d9d4a9f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import needed libaries\n",
    "import os\n",
    "import boto3\n",
    "import mlflow\n",
    "import time\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from snowML.datapipe import snow_types as st\n",
    "from snowML.datapipe import get_geos as gg\n",
    "from snowML.datapipe import data_utils as du\n",
    "from snowML.datapipe import get_dem as gd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7685f08a-2239-4e0c-9598-65341d3cb0e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize erathengine credentials\n",
    "import ee\n",
    "ee.Authenticate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5ba103-68d9-4624-b93d-aa41d9e0130f",
   "metadata": {},
   "source": [
    "# Step 1 Get MLFlow Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77a4451e-b371-438b-8a1f-c8a712bf5af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to retrieve metrics from ML server \n",
    "def load_ml_metrics(tracking_uri, run_id, save_local=False):\n",
    "    mlflow.set_tracking_uri(tracking_uri)\n",
    "    client = mlflow.MlflowClient()\n",
    "    # Get all metric keys from the run\n",
    "    run_data = client.get_run(run_id).data\n",
    "    metric_keys = run_data.metrics.keys()\n",
    "    # Retrieve full metric history for each key\n",
    "    all_metrics = []\n",
    "    for metric in metric_keys:\n",
    "        history = client.get_metric_history(run_id, metric)\n",
    "        for record in history:\n",
    "            all_metrics.append({\n",
    "                \"Metric\": metric,\n",
    "                \"Step\": record.step,\n",
    "                \"Value\": record.value\n",
    "            })\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    metrics_df = pd.DataFrame(all_metrics)\n",
    "    \n",
    "    # Save to CSV if needed\n",
    "    if save_local:\n",
    "        f_out = f\"run_id_data/metrics_from_{run_id}.csv\"\n",
    "        metrics_df.to_csv(f_out, index=False)\n",
    "\n",
    "    return metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f76a38a-ea28-4900-bb00-0db9fabdf52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to extract only a specific metric\n",
    "def extract_metric(df, metric_name):\n",
    "    \"\"\"Extracts rows where the Metric column ends with 'metric_name' and returns only Metric and Value columns.\"\"\"\n",
    "    return df[df['Metric'].str.endswith(metric_name)][['Metric', 'Value']].sort_values(by='Metric')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55dda699-c626-496e-b2eb-a9cfaa9cb98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to extract data from a given epoch \n",
    "def summarize_by_step(df, step, agg_lev = 12):\n",
    "    df_filtered = df[df[\"Step\"] == step].copy()\n",
    "    df_filtered[\"Metric_Type\"] = df_filtered[\"Metric\"].str.extract(r\"(test_mse|test_kge|train_mse|train_kge)\")\n",
    "    df_filtered[\"HUC_ID\"] = df_filtered[\"Metric\"].str.extract(fr\"(\\d{{{agg_lev}}})\")  \n",
    "\n",
    "    # Take mean across HUC_ID if duplicates exist\n",
    "    if df_filtered.duplicated(subset=[\"HUC_ID\", \"Metric_Type\"]).any():\n",
    "        df_filtered = df_filtered.groupby([\"HUC_ID\", \"Metric_Type\"], as_index=False)[\"Value\"].mean()\n",
    "\n",
    "    df_pivot = df_filtered.pivot(index=\"HUC_ID\", columns=\"Metric_Type\", values=\"Value\")\n",
    "    df_pivot.columns = [\"Test KGE\", \"Test MSE\", \"Train KGE\", \"Train_MSE\"]\n",
    "    df_pivot_sorted = df_pivot.sort_index()\n",
    "    df_selected = df_pivot_sorted[[\"Test MSE\", \"Test KGE\"]]\n",
    "    # print(df_selected)\n",
    "    return df_selected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1697267-a26c-477d-812c-972162558357",
   "metadata": {},
   "source": [
    "**Note** To extract metrics from the MLFlow Tracking Server you must be logged in to AWS with access to the MLFlow Server.  If this is not the case, use the upload from local option.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e79ec35d-0577-4d72-a62d-642f354682d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set mlFlow tracking server\n",
    "tracking_uri = \"arn:aws:sagemaker:us-west-2:677276086662:mlflow-tracking-server/dawgsML\"\n",
    "# define our run_ids by recognizable names; local training spread over 3 runs \n",
    "multi_hucs = \"7bc43aac04414e989fb0fb3a244b138e\" # lyrical-wren; 30 epochs, all M&M hucs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d1df458-3447-4076-99d8-d97551d653aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6750, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Step</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_kge_170602070902</td>\n",
       "      <td>0</td>\n",
       "      <td>0.826216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_kge_170602070902</td>\n",
       "      <td>1</td>\n",
       "      <td>0.876016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Metric  Step     Value\n",
       "0  test_kge_170602070902     0  0.826216\n",
       "1  test_kge_170602070902     1  0.876016"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metrics  = load_ml_metrics(tracking_uri, multi_hucs, save_local=True)\n",
    "print(df_metrics.shape)\n",
    "df_metrics.head(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
