{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a263a94-49b4-4525-9ac3-8c40e1de4533",
   "metadata": {},
   "source": [
    "# Notebook to explore inherent model variance "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6db611-f956-4448-97da-2ceb4c8e0afb",
   "metadata": {},
   "source": [
    "# Step 0 - Prepare Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41df601e-19ff-41ad-92bf-c1bb6c3cb71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time \n",
    "import json\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "from snowML.datapipe.utils import data_utils as du\n",
    "from snowML.LSTM import set_hyperparams as sh\n",
    "from snowML.LSTM import LSTM_pre_process as pp \n",
    "from snowML.LSTM import LSTM_train as LSTM_tr\n",
    "from snowML.LSTM import LSTM_metrics as met\n",
    "from snowML.LSTM import LSTM_plot3 as plot3\n",
    "from snowML.Scripts import local_training_mixed_loss as ml\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081965c8-5ce1-4263-b1f1-03d1e1771592",
   "metadata": {},
   "source": [
    "# Step 1 - Define HyperParams and Test Huc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09a9570d-eb32-4965-a1c5-80747098e46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "huc = '170200090101' ## Chelan, maritime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d149ff18-f175-4fb9-82c3-0164ee14565e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hidden_size': 64,\n",
       " 'num_class': 1,\n",
       " 'num_layers': 1,\n",
       " 'dropout': 0.5,\n",
       " 'learning_rate': 0.001,\n",
       " 'n_epochs': 10,\n",
       " 'lookback': 180,\n",
       " 'batch_size': 32,\n",
       " 'n_steps': 1,\n",
       " 'num_workers': 8,\n",
       " 'var_list': ['mean_pr', 'mean_tair'],\n",
       " 'expirement_name': 'MultipleRunsSameHuc',\n",
       " 'loss_type': 'mse',\n",
       " 'mse_lambda_start': 1,\n",
       " 'mse_lambda_end': 0.5,\n",
       " 'train_size_dimension': 'time',\n",
       " 'train_size_fraction': 0.67,\n",
       " 'mlflow_tracking_uri': 'arn:aws:sagemaker:us-west-2:677276086662:mlflow-tracking-server/dawgsML',\n",
       " 'recursive_predict': False,\n",
       " 'lag_days': 30,\n",
       " 'lag_swe_var_idx': 3,\n",
       " 'filter_dates': ['1984-10-01', '2021-09-30'],\n",
       " 'custom delta': 0.04,\n",
       " 'UCLA': False,\n",
       " 'Stop_Loss': False,\n",
       " 'KGE_target': 0.9,\n",
       " 'MLFLOW_ON': True}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set hyperparams\n",
    "# load base line params \n",
    "params = sh.create_hyper_dict()\n",
    "# reset the ones we care about\n",
    "params[\"learning_rate\"] = .001\n",
    "params[\"n_epochs\"] = 10    \n",
    "params[\"batch_size\"] = 32\n",
    "params[\"var_list\"] = ['mean_pr', 'mean_tair']\n",
    "params[\"expirement_name\"] = \"MultipleRunsSameHuc\"\n",
    "params[\"loss_type\"] = \"mse\"\n",
    "params[\"train_size_dimension\"] = \"time\"\n",
    "params[\"train_size_fraction\"] = .67\n",
    "params[\"recursive_predict\"] = False \n",
    "params[\"UCLA\"] = False # start w/ UA data then update \n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e94f9e-c8cc-4fc5-bec6-6e65e2e91bcf",
   "metadata": {},
   "source": [
    "# Step 2 - Define model functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6fd59871-6c73-476c-9fed-4080c8026866",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(huc, params): \n",
    "    # normalize the data and create train/test split \n",
    "    df_dict = pp.pre_process_separate([huc], params[\"var_list\"], UCLA = params[\"UCLA\"], filter_dates=params[\"filter_dates\"])\n",
    "    train_size_frac = params[\"train_size_fraction\"]\n",
    "    df = df_dict[huc]\n",
    "    df_train, _, _, _ = pp.train_test_split_time(df, train_size_frac)\n",
    "    return df_dict, df_train\n",
    "\n",
    "def train_model (df_train, params): \n",
    "    model_dawgs, optimizer_dawgs, loss_fn_dawgs = ml.initialize_model(params)\n",
    "   \n",
    "    for epoch in range(params[\"n_epochs\"]):\n",
    "        # for local training, call fine_tune instead of pre_train\n",
    "        print(f\"Training in epoch {epoch}\")\n",
    "        LSTM_tr.fine_tune(\n",
    "            model_dawgs,\n",
    "            optimizer_dawgs,\n",
    "            loss_fn_dawgs,\n",
    "            df_train,\n",
    "            params,\n",
    "            epoch\n",
    "            )\n",
    "    return model_dawgs \n",
    "\n",
    "def evaluate(model_dawgs_trained, df_dict, huc, params):\n",
    "    if params[\"UCLA\"]:\n",
    "        suffix = \"UCLA\"\n",
    "    else: \n",
    "        suffix = \"UA\"\n",
    "    data, y_tr_pred, y_te_pred, y_tr_true, y_te_true,  y_te_pred_recur, train_size, = LSTM_tr.predict_prep (model_dawgs_trained,\n",
    "                df_dict, huc, params)\n",
    "    metric_dict_test = met.calc_metrics(y_te_true, y_te_pred, metric_type = f\"test_{suffix}\")\n",
    "    if y_te_pred_recur is not None:\n",
    "        metric_dict_test_recur = met.calc_metrics(y_te_true, y_te_pred_recur, metric_type = f\"test_recur_{suffix}\")\n",
    "        combined_dict = {**metric_dict_test, **metric_dict_test_recur}\n",
    "    else:\n",
    "        combined_dict = metric_dict_test\n",
    "        \n",
    "    return combined_dict, data, y_tr_pred, y_te_pred, y_tr_true, y_te_true, y_te_pred_recur, train_size\n",
    "\n",
    "\n",
    "def combine_results(data, y_tr_pred, y_te_pred, y_tr_true, y_te_true, y_te_pred_recur, train_size, params):\n",
    "    results_df = data[[\"mean_swe\"]].copy()\n",
    "    results_df[\"y_tr_pred\"] = list(y_tr_pred) + [float('nan')] * (len(results_df) - len(y_tr_pred))\n",
    "    results_df[\"y_te_pred\"] = [float('nan')] * (train_size+params[\"lookback\"]) + list(y_te_pred)\n",
    "    results_df[\"y_tr_true\"] = list(y_tr_true) + [float('nan')] * (len(results_df) - len(y_tr_true))\n",
    "    results_df[\"y_te_true\"] = [float('nan')] *(train_size+params[\"lookback\"]) + list(y_te_true)\n",
    "    return results_df\n",
    "\n",
    "def label_results(df, suffix):\n",
    "    df = df.add_suffix(f\"_{suffix}\")\n",
    "    return df\n",
    "\n",
    "def run_one(huc, params, data_type = \"UA\"): \n",
    "    if data_type == \"UCLA\": \n",
    "        params[\"UCLA\"] = True \n",
    "        suffix = \"UCLA\" \n",
    "    else: \n",
    "        params[\"UCLA\"] = False\n",
    "        suffix = \"UA\"\n",
    "    df_dict, df_train = pre_process(huc, params)\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", UserWarning) # ignore warning about drop param being irrelevant with single deep layer\n",
    "        model_dawgs_trained = train_model(df_train, params)\n",
    "    combined_dict, data, y_tr_pred, y_te_pred, y_tr_true, y_te_true, y_te_pred_recur, tr_size = evaluate(model_dawgs_trained, df_dict, huc, params)\n",
    "    #df_results = combine_results(data, y_tr_pred, y_te_pred, y_tr_true, y_te_true, y_te_pred_recur, tr_size, params)\n",
    "    #df_results = label_results(df_results, suffix)\n",
    "    #return combined_dict, df_results, tr_size\n",
    "    return combined_dict\n",
    "\n",
    "def dict_to_single_row_df(data_dict):\n",
    "    \"\"\"\n",
    "    Transforms a dictionary into a pandas DataFrame with one row.\n",
    "    \n",
    "    Parameters:\n",
    "        data_dict (dict): The dictionary to transform.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with one row and keys as column names.\n",
    "    \"\"\"\n",
    "    return pd.DataFrame([data_dict])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adad2749-60ac-4a59-a1dd-7cac337799b2",
   "metadata": {},
   "source": [
    "# Step 3 - Get Results Sample Huc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3806a53-cc0f-4435-b25c-6c9f866020c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "huc = '170200090101'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68220060-4e48-42ef-8a80-000c452490c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training in epoch 0\n",
      "Training in epoch 1\n",
      "Training in epoch 2\n",
      "Training in epoch 3\n",
      "Training in epoch 4\n",
      "Training in epoch 5\n",
      "Training in epoch 6\n",
      "Training in epoch 7\n",
      "Training in epoch 8\n",
      "Training in epoch 9\n"
     ]
    }
   ],
   "source": [
    "results = run_one(huc, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9cf564c0-7a84-42bf-90f6-f2e248057e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_UA_mse': 0.009720983,\n",
       " 'test_UA_kge': 0.9385536544028658,\n",
       " 'test_UA_r2': 0.9444973777293773,\n",
       " 'test_UA_mae': 0.06340153}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d77f2f7-8ea6-4911-a1ab-726f4d234381",
   "metadata": {},
   "source": [
    "# Now Try The Module "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "19033cb3-fb7d-404d-9423-c4e7f22a51fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowML.Scripts import multi_run_single_huc as mrsh\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1a16198e-7f4b-4b14-bb8d-68908b230f14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'snowML.Scripts.multi_run_single_huc' from '/home/suetboyd/Capstone/SnowML/src/snowML/Scripts/multi_run_single_huc.py'>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(mrsh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a1463cb9-8b29-4d29-a2c6-e9b9f905b759",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suetboyd/miniconda3/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "evaluating on huc 170200090101\n",
      "test_mse: 0.04752444848418236\n",
      "test_kge: 0.846424696822091\n",
      "test_r2: 0.728655864644969\n",
      "test_mae: 0.15049424767494202\n",
      "train_mse: 0.057158514857292175\n",
      "train_kge: 0.8164002698266688\n",
      "train_r2: 0.6847067845297408\n",
      "train_mae: 0.1590631902217865\n",
      "Epoch 1\n",
      "evaluating on huc 170200090101\n",
      "test_mse: 0.026343023404479027\n",
      "test_kge: 0.9238446355859425\n",
      "test_r2: 0.8495926910831191\n",
      "test_mae: 0.10974498838186264\n",
      "train_mse: 0.03684147819876671\n",
      "train_kge: 0.895491638441111\n",
      "train_r2: 0.7967779667238732\n",
      "train_mae: 0.12370743602514267\n",
      "Epoch 2\n",
      "evaluating on huc 170200090101\n",
      "test_mse: 0.020172692835330963\n",
      "test_kge: 0.9077584150721032\n",
      "test_r2: 0.884822614828817\n",
      "test_mae: 0.09553276747465134\n",
      "train_mse: 0.023958703503012657\n",
      "train_kge: 0.8836893011589392\n",
      "train_r2: 0.8678409154877746\n",
      "train_mae: 0.10758419334888458\n",
      "Epoch 3\n",
      "evaluating on huc 170200090101\n",
      "test_mse: 0.015524337999522686\n",
      "test_kge: 0.9412891702763703\n",
      "test_r2: 0.9113627164450626\n",
      "test_mae: 0.0756797045469284\n",
      "train_mse: 0.02272115647792816\n",
      "train_kge: 0.9135775618437659\n",
      "train_r2: 0.8746673625706548\n",
      "train_mae: 0.09568458795547485\n",
      "Epoch 4\n",
      "evaluating on huc 170200090101\n",
      "test_mse: 0.01772957667708397\n",
      "test_kge: 0.9416095142858909\n",
      "test_r2: 0.8987717596988376\n",
      "test_mae: 0.08152320235967636\n",
      "train_mse: 0.022177359089255333\n",
      "train_kge: 0.9331651238298716\n",
      "train_r2: 0.8776670221059945\n",
      "train_mae: 0.09399514645338058\n",
      "Epoch 5\n",
      "evaluating on huc 170200090101\n",
      "test_mse: 0.016386007890105247\n",
      "test_kge: 0.8971729793638851\n",
      "test_r2: 0.906442962340899\n",
      "test_mae: 0.0801292434334755\n",
      "train_mse: 0.01419117208570242\n",
      "train_kge: 0.9435737299767518\n",
      "train_r2: 0.9217197843346868\n",
      "train_mae: 0.07479707151651382\n",
      "Epoch 6\n",
      "evaluating on huc 170200090101\n",
      "test_mse: 0.01762315258383751\n",
      "test_kge: 0.9394653728395891\n",
      "test_r2: 0.8993793999046347\n",
      "test_mae: 0.08296354115009308\n",
      "train_mse: 0.009663435630500317\n",
      "train_kge: 0.9563407397302273\n",
      "train_r2: 0.946695333035874\n",
      "train_mae: 0.06047012284398079\n",
      "Epoch 7\n",
      "evaluating on huc 170200090101\n",
      "test_mse: 0.01410937774926424\n",
      "test_kge: 0.9514047581352054\n",
      "test_r2: 0.9194415345232394\n",
      "test_mae: 0.07497686892747879\n",
      "train_mse: 0.008692431263625622\n",
      "train_kge: 0.9509452810676898\n",
      "train_r2: 0.9520515003087255\n",
      "train_mae: 0.0585310123860836\n",
      "Epoch 8\n",
      "evaluating on huc 170200090101\n",
      "test_mse: 0.01986660808324814\n",
      "test_kge: 0.9094270939651318\n",
      "test_r2: 0.8865702294602337\n",
      "test_mae: 0.0830937847495079\n",
      "train_mse: 0.014681380242109299\n",
      "train_kge: 0.8839517226157239\n",
      "train_r2: 0.919015737348412\n",
      "train_mae: 0.0702134519815445\n",
      "Epoch 9\n",
      "evaluating on huc 170200090101\n",
      "test_mse: 0.017223931849002838\n",
      "test_kge: 0.9092803592121643\n",
      "test_r2: 0.901658775889191\n",
      "test_mae: 0.08032221347093582\n",
      "train_mse: 0.012052785605192184\n",
      "train_kge: 0.8551491495769864\n",
      "train_r2: 0.9335153788990351\n",
      "train_mae: 0.06656501442193985\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8551491495769864,\n",
       " {'test_mse': 0.017223932,\n",
       "  'test_kge': 0.9092803592121643,\n",
       "  'test_r2': 0.901658775889191,\n",
       "  'test_mae': 0.08032221})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrsh.run_multi_exp(huc, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b71ecfb-6ea1-4d1d-a49c-46379369fbc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
